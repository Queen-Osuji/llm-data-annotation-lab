# Inter-Annotator Agreement

To ensure annotation quality, multiple annotators label the same samples.

Agreement is measured using:
- Percentage agreement
- Cohenâ€™s Kappa (when applicable)

Disagreements are reviewed and resolved through consensus.

