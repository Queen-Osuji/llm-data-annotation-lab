
# LLM Data Annotation Lab

This repository demonstrates real-world AI data annotation workflows used to train, evaluate, and align large language models.

## What This Shows
- Intent classification
- Toxicity detection
- Factuality verification
- Human-in-the-loop AI training
- Annotation guidelines and quality control

## Why It Matters
High-quality labeled data is the foundation of safe and reliable AI systems.
This lab mirrors annotation pipelines used by companies like OpenAI, Anthropic, and NVIDIA.
